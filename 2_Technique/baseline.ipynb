{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7fe31f",
   "metadata": {},
   "source": [
    "# Phase 2: Expressive Techniques Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535c734",
   "metadata": {},
   "source": [
    "## A) \"Initial experiments\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b33cab",
   "metadata": {},
   "source": [
    "### Recreate our baseline architecture (cred: Stefani et. al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Gather Dependencies (ensure these are installed)\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 2: Prepare Your Data Pipeline\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_features_from_audio(file_path, n_mfcc=20, n_chroma=12, n_spectral_contrast=7):\n",
    "    \"\"\"\n",
    "    Extracts a 180-dimensional feature vector from an audio file.\n",
    "    This is an example implementation; the exact features should be tuned.\n",
    "\n",
    "    To get to 180 dimensions, we concatenate:\n",
    "    - MFCC (mean + std) = 20 * 2 = 40\n",
    "    - Chroma STFT (mean + std) = 12 * 2 = 24\n",
    "    - Spectral Contrast (mean + std) = 7 * 2 = 14\n",
    "    - Spectral Centroid (mean + std) = 1 * 2 = 2\n",
    "    - Spectral Bandwidth (mean + std) = 1 * 2 = 2\n",
    "    - Spectral Rolloff (mean + std) = 1 * 2 = 2\n",
    "    - Zero Crossing Rate (mean + std) = 1 * 2 = 2\n",
    "    - Mel Spectrogram (mean + std) = 128 * 1 = 128 (using only mean for this one to save space)\n",
    "    Total dimensions: 40 + 24 + 14 + 2 + 2 + 2 + 2 = 86.\n",
    "\n",
    "    To reach 180, we need more features. Let's use larger MFCCs and Mel Spectrograms.\n",
    "    New plan:\n",
    "    - MFCC (mean + std) = 40 * 2 = 80\n",
    "    - Mel Spectrogram (mean + std) = 40 * 2 = 80\n",
    "    - Chroma STFT (mean + std) = 10 * 2 = 20\n",
    "    Total = 180.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, mono=True)\n",
    "\n",
    "        # MFCCs (80 dims)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        mfccs_mean = np.mean(mfccs, axis=1)\n",
    "        mfccs_std = np.std(mfccs, axis=1)\n",
    "\n",
    "        # Mel Spectrogram (80 dims)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40)\n",
    "        mel_spec_mean = np.mean(mel_spec, axis=1)\n",
    "        mel_spec_std = np.std(mel_spec, axis=1)\n",
    "\n",
    "        # Chroma Features (20 dims)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=10)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "        chroma_std = np.std(chroma, axis=1)\n",
    "\n",
    "        # Concatenate all features to create the final 180-dim vector\n",
    "        feature_vector = np.concatenate([\n",
    "            mfccs_mean, mfccs_std,\n",
    "            mel_spec_mean, mel_spec_std,\n",
    "            chroma_mean, chroma_std\n",
    "        ])\n",
    "\n",
    "        return feature_vector\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 3: Implement Model A in TensorFlow/Keras\n",
    "# ==============================================================================\n",
    "\n",
    "def create_model_A(input_shape=(180,), num_classes=8):\n",
    "    \"\"\"\n",
    "    Creates and compiles the Keras model described as Model A.\n",
    "    \"\"\"\n",
    "    model = Sequential(name=\"Model_A_Stefani_et_al\")\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "    # Four hidden layers\n",
    "    for _ in range(4):\n",
    "        model.add(Dense(800, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create an instance of the model and print its summary\n",
    "model = create_model_A()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec53b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# This command lists all physical devices visible to TensorFlow\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpu_devices:\n",
    "    print(f\"TensorFlow has found {len(gpu_devices)} GPU(s):\")\n",
    "    for device in gpu_devices:\n",
    "        print(f\" - {device}\")\n",
    "    # When you run your training, TensorFlow will automatically print\n",
    "    # log messages indicating it's creating tensors on the GPU.\n",
    "else:\n",
    "    print(\"‼️ TensorFlow did NOT find any GPUs.\")\n",
    "    print(\"Training will run on the CPU, which will be much slower.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 4: Data Loading, Splitting, and Training (Full Implementation)\n",
    "# ==============================================================================\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "def load_and_split_data(data_dir, folds_json_path):\n",
    "    \"\"\"\n",
    "    Loads all audio, extracts features, and splits data according to a JSON file.\n",
    "    \"\"\"\n",
    "    # 1. Create a mapping from class name (folder name) to integer index\n",
    "    label_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    label_map = {name: i for i, name in enumerate(label_names)}\n",
    "    print(f\"Found {len(label_map)} classes: {label_names}\")\n",
    "\n",
    "    # 2. Process ALL wav files and store features/labels in a dictionary.\n",
    "    #    This pre-computation makes it easy to look up data for the splits later.\n",
    "    all_data = {}\n",
    "    print(\"\\nProcessing all audio files... this may take a while.\")\n",
    "    for label_name, label_idx in label_map.items():\n",
    "        class_dir = os.path.join(data_dir, label_name)\n",
    "        for fname in tqdm(os.listdir(class_dir), desc=f\"Processing '{label_name}'\"):\n",
    "            if fname.endswith('.wav'):\n",
    "                fpath = os.path.join(class_dir, fname)\n",
    "                feature_vec = extract_features_from_audio(fpath)\n",
    "                if feature_vec is not None and feature_vec.shape[0] == 180:\n",
    "                    # Store feature vector and label index, keyed by the simple filename\n",
    "                    all_data[fname] = (feature_vec, label_idx)\n",
    "\n",
    "    print(f\"\\nSuccessfully processed {len(all_data)} audio files.\")\n",
    "\n",
    "    # 3. Load the JSON file that defines the train/test splits\n",
    "    with open(folds_json_path, 'r') as f:\n",
    "        splits = json.load(f)\n",
    "    \n",
    "    # 4. Create the dataset for each fold using the pre-computed features\n",
    "    folded_data = []\n",
    "    print(\"Building datasets for each fold based on JSON splits...\")\n",
    "    for fold_name in sorted(splits.keys()):\n",
    "        train_files = splits[fold_name]['train']\n",
    "        test_files = splits[fold_name]['test']\n",
    "\n",
    "        X_train, y_train = [], []\n",
    "        for fname in train_files:\n",
    "            if fname in all_data:\n",
    "                features, label = all_data[fname]\n",
    "                X_train.append(features)\n",
    "                y_train.append(label)\n",
    "\n",
    "        X_test, y_test = [], []\n",
    "        for fname in test_files:\n",
    "            if fname in all_data:\n",
    "                features, label = all_data[fname]\n",
    "                X_test.append(features)\n",
    "                y_test.append(label)\n",
    "        \n",
    "        folded_data.append({\n",
    "            'fold_name': fold_name,\n",
    "            'X_train': np.array(X_train), 'y_train': np.array(y_train),\n",
    "            'X_test': np.array(X_test), 'y_test': np.array(y_test)\n",
    "        })\n",
    "        print(f\" -> Loaded {fold_name}: {len(X_train)} train samples, {len(X_test)} test samples.\")\n",
    "        \n",
    "    return folded_data, len(label_map)\n",
    "\n",
    "# --- Main Execution ---\n",
    "DATA_ROOT = \"\"\n",
    "FOLDS_JSON = \"\"\n",
    "\n",
    "try:\n",
    "    all_folded_data, num_classes = load_and_split_data(DATA_ROOT, FOLDS_JSON)\n",
    "    \n",
    "    # --- Training Loop ---\n",
    "    histories = []\n",
    "    for i, fold in enumerate(all_folded_data):\n",
    "        print(f\"\\n----------- TRAINING FOLD {i+1}/{len(all_folded_data)} ({fold['fold_name']}) -----------\")\n",
    "        \n",
    "        X_train, y_train = fold['X_train'], fold['y_train']\n",
    "        X_test, y_test = fold['X_test'], fold['y_test']\n",
    "        \n",
    "        # One-hot encode the labels for the current fold\n",
    "        y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "        y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "        \n",
    "        # Create a new, fresh model for each fold to avoid information leakage\n",
    "        model = create_model_A(num_classes=num_classes)\n",
    "\n",
    "        # This will save the best model of this fold to a uniquely named file\n",
    "        checkpoint_filepath = f'models/best_model_fold_{i+1}.h5'\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=False,  # Save the full model (architecture + weights)\n",
    "            monitor='val_accuracy',   # The metric to monitor\n",
    "            mode='max',               # We want to MAXIMIZE accuracy\n",
    "            save_best_only=True,      # Only save when the metric improves\n",
    "            verbose=1)\n",
    "\n",
    "        # Fit data to model, now including the callback\n",
    "        history = model.fit(X_train, y_train_cat,\n",
    "                            batch_size=64,\n",
    "                            epochs=50, \n",
    "                            validation_data=(X_test, y_test_cat),\n",
    "                            verbose=1,\n",
    "                            callbacks=[model_checkpoint_callback]) # Pass the callback here\n",
    "        \n",
    "        histories.append(history)\n",
    "\n",
    "    print(\"\\n✅ Completed cross-validation training.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"=\"*60)\n",
    "    print(\"‼️ ERROR: Data directory or folds.json not found.\")\n",
    "    print(f\"Please ensure your data is in a folder named '{DATA_ROOT}'\")\n",
    "    print(f\"and your splits file is at '{FOLDS_JSON}'.\")\n",
    "    print(\"Cannot proceed with training.\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a38ba3",
   "metadata": {},
   "source": [
    "### Baseline + regularization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 1: All Imports\n",
    "# ==============================================================================\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 2: Feature Extraction Function\n",
    "# ==============================================================================\n",
    "def extract_features_from_audio(file_path, n_mfcc=40, n_mels=40, n_chroma=10):\n",
    "    \"\"\"\n",
    "    Extracts a 180-dimensional feature vector from an audio file.\n",
    "    This combines the mean and standard deviation of MFCCs, Mel Spectrograms,\n",
    "    and Chroma features to create the final vector.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, mono=True)\n",
    "        \n",
    "        # MFCCs (mean + std = 80 dims)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfccs_mean = np.mean(mfccs, axis=1)\n",
    "        mfccs_std = np.std(mfccs, axis=1)\n",
    "\n",
    "        # Mel Spectrogram (mean + std = 80 dims)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        mel_spec_mean = np.mean(mel_spec, axis=1)\n",
    "        mel_spec_std = np.std(mel_spec, axis=1)\n",
    "\n",
    "        # Chroma Features (mean + std = 20 dims)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=n_chroma)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "        chroma_std = np.std(chroma, axis=1)\n",
    "\n",
    "        # Concatenate all features to create the final 180-dim vector\n",
    "        feature_vector = np.concatenate([\n",
    "            mfccs_mean, mfccs_std,\n",
    "            mel_spec_mean, mel_spec_std,\n",
    "            chroma_mean, chroma_std\n",
    "        ])\n",
    "        return feature_vector\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 3: Regularized Model Creation Function\n",
    "# ==============================================================================\n",
    "def create_model_A(input_shape=(180,), num_classes=9, dropout_rate=0.4, l2_lambda=1e-4):\n",
    "    \"\"\"\n",
    "    Creates and compiles the Keras model with Dropout and L2 regularization.\n",
    "    \"\"\"\n",
    "    model = Sequential(name=\"Model_A_Regularized\")\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "    # Four hidden layers with regularization\n",
    "    for _ in range(4):\n",
    "        model.add(Dense(800, activation='relu', kernel_regularizer=l2(l2_lambda)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 4: Data Loading and Splitting Function\n",
    "# ==============================================================================\n",
    "def load_and_split_data(data_dir, folds_json_path):\n",
    "    \"\"\"\n",
    "    Loads all audio, extracts features, and splits data according to a JSON file.\n",
    "    \"\"\"\n",
    "    label_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    label_map = {name: i for i, name in enumerate(label_names)}\n",
    "    print(f\"Found {len(label_map)} classes: {label_names}\")\n",
    "\n",
    "    all_data = {}\n",
    "    print(\"\\nProcessing all audio files... this may take a while.\")\n",
    "    for label_name, label_idx in label_map.items():\n",
    "        class_dir = os.path.join(data_dir, label_name)\n",
    "        for fname in tqdm(os.listdir(class_dir), desc=f\"Processing '{label_name}'\"):\n",
    "            if fname.endswith('.wav'):\n",
    "                fpath = os.path.join(class_dir, fname)\n",
    "                feature_vec = extract_features_from_audio(fpath)\n",
    "                if feature_vec is not None and feature_vec.shape[0] == 180:\n",
    "                    all_data[fname] = (feature_vec, label_idx)\n",
    "\n",
    "    print(f\"\\nSuccessfully processed {len(all_data)} audio files.\")\n",
    "\n",
    "    with open(folds_json_path, 'r') as f:\n",
    "        splits = json.load(f)\n",
    "    \n",
    "    folded_data = []\n",
    "    print(\"Building datasets for each fold based on JSON splits...\")\n",
    "    for fold_name in sorted(splits.keys()):\n",
    "        train_files = splits[fold_name]['train']\n",
    "        test_files = splits[fold_name]['test']\n",
    "\n",
    "        X_train, y_train = [], []\n",
    "        for fname in train_files:\n",
    "            if fname in all_data:\n",
    "                features, label = all_data[fname]\n",
    "                X_train.append(features)\n",
    "                y_train.append(label)\n",
    "\n",
    "        X_test, y_test = [], []\n",
    "        for fname in test_files:\n",
    "            if fname in all_data:\n",
    "                features, label = all_data[fname]\n",
    "                X_test.append(features)\n",
    "                y_test.append(label)\n",
    "        \n",
    "        folded_data.append({\n",
    "            'fold_name': fold_name,\n",
    "            'X_train': np.array(X_train), 'y_train': np.array(y_train),\n",
    "            'X_test': np.array(X_test), 'y_test': np.array(y_test)\n",
    "        })\n",
    "        print(f\" -> Loaded {fold_name}: {len(X_train)} train samples, {len(X_test)} test samples.\")\n",
    "        \n",
    "    return folded_data, len(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 5: Main Training Execution\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_ROOT = \"\"\n",
    "FOLDS_JSON = \"\"\n",
    "MODEL_OUTPUT_DIR = 'models_regularized'\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True) \n",
    "\n",
    "# --- Verification and Training ---\n",
    "try:\n",
    "    # Print model summary to verify architecture\n",
    "    print(\"Model Architecture:\")\n",
    "    model_instance = create_model_A()\n",
    "    model_instance.summary()\n",
    "\n",
    "    # Load data\n",
    "    all_folded_data, num_classes = load_and_split_data(DATA_ROOT, FOLDS_JSON)\n",
    "    print(\"num_classes:\", num_classes)\n",
    "    \n",
    "    # --- Training Loop ---\n",
    "    histories = []\n",
    "    for i, fold_data in enumerate(all_folded_data):\n",
    "        fold_name = fold_data['fold_name']\n",
    "        print(f\"\\n----------- TRAINING FOLD {i+1}/{len(all_folded_data)} ({fold_name}) -----------\")\n",
    "        \n",
    "        X_train, y_train = fold_data['X_train'], fold_data['y_train']\n",
    "        X_test, y_test = fold_data['X_test'], fold_data['y_test']\n",
    "        \n",
    "        y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "        y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "        \n",
    "        model = create_model_A(num_classes=num_classes, dropout_rate=0.5, l2_lambda=1e-3)\n",
    "\n",
    "        checkpoint_filepath = os.path.join(MODEL_OUTPUT_DIR, f'best_model_{fold_name}.h5')\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True)\n",
    "            \n",
    "        early_stopping_callback = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            verbose=1,\n",
    "            restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(X_train, y_train_cat,\n",
    "                            batch_size=64,\n",
    "                            epochs=1000,\n",
    "                            validation_data=(X_test, y_test_cat),\n",
    "                            verbose=0,\n",
    "                            callbacks=[model_checkpoint_callback, early_stopping_callback])\n",
    "        \n",
    "        histories.append(history)\n",
    "\n",
    "    print(f\"\\n✅ Completed cross-validation training. Best models saved in '{MODEL_OUTPUT_DIR}/'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"=\"*60)\n",
    "    print(\"‼️ ERROR: Data directory or folds.json not found.\")\n",
    "    print(f\"Please ensure your data is in a folder named '{DATA_ROOT}'\")\n",
    "    print(f\"and your splits file is at '{FOLDS_JSON}'.\")\n",
    "    print(\"Cannot proceed with training.\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4c5ed",
   "metadata": {},
   "source": [
    "### Inference on IDMT-SMT-Guitar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# 0. Configuration\n",
    "# ==============================================================================\n",
    "\n",
    "MODEL_TO_EVALUATE = \"\"\n",
    "IDMT_AUDIO_DIR = \"\"\n",
    "IDMT_XML_DIR = \"\"\n",
    "\n",
    "MAGCIL_CLASSES = [\n",
    "    'alternate picking', 'bend', 'hammer on', 'legato', 'pull off',\n",
    "    'slide', 'sweep picking', 'tapping', 'vibrato', 'other'  # Ensure 'other' included\n",
    "]\n",
    "\n",
    "EVAL_CLASSES = ['bend', 'slide', 'vibrato', 'other']\n",
    "EVAL_CLASS_INDICES = [MAGCIL_CLASSES.index(c) for c in EVAL_CLASSES]\n",
    "OTHER_IDX = MAGCIL_CLASSES.index('other')\n",
    "\n",
    "IDMT_TO_MAGCIL_IDX = {\n",
    "    'be': MAGCIL_CLASSES.index('bend'),\n",
    "    'sl': MAGCIL_CLASSES.index('slide'),\n",
    "    'vi': MAGCIL_CLASSES.index('vibrato'),\n",
    "    # All other common codes mapped to 'other'\n",
    "    'pi': OTHER_IDX, 'ha': OTHER_IDX, 'dn': OTHER_IDX, 'no': OTHER_IDX,\n",
    "    'fs': OTHER_IDX, 'mu': OTHER_IDX, # Add more if needed\n",
    "}\n",
    "\n",
    "print(f\"Model evaluated on these classes: {EVAL_CLASSES}\")\n",
    "print(f\"IDMT to model index mapping: {IDMT_TO_MAGCIL_IDX}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Helper Functions\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_features_from_segmented_audio(y_segment, sr):\n",
    "    try:\n",
    "        if len(y_segment) < 2048:\n",
    "            return None\n",
    "        mfccs = librosa.feature.mfcc(y=y_segment, sr=sr, n_mfcc=40)\n",
    "        mfccs_mean, mfccs_std = np.mean(mfccs, axis=1), np.std(mfccs, axis=1)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y_segment, sr=sr, n_mels=40)\n",
    "        mel_spec_mean, mel_spec_std = np.mean(mel_spec, axis=1), np.std(mel_spec, axis=1)\n",
    "        chroma = librosa.feature.chroma_stft(y=y_segment, sr=sr, n_chroma=10)\n",
    "        chroma_mean, chroma_std = np.mean(chroma, axis=1), np.std(chroma, axis=1)\n",
    "        feature_vector = np.concatenate([\n",
    "            mfccs_mean, mfccs_std, mel_spec_mean, mel_spec_std, chroma_mean, chroma_std\n",
    "        ])\n",
    "        return feature_vector\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_idmt_xml(xml_path):\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for event in root.findall('.//event'):\n",
    "            onset_tag = event.find('onsetSec')\n",
    "            offset_tag = event.find('offsetSec')\n",
    "            technique_tag = event.find('expressionStyle')\n",
    "            if onset_tag is not None and offset_tag is not None and technique_tag is not None:\n",
    "                onset = float(onset_tag.text)\n",
    "                offset = float(offset_tag.text)\n",
    "                technique = technique_tag.text.lower().strip()\n",
    "                yield {'onset': onset, 'offset': offset, 'technique': technique}\n",
    "    except ET.ParseError:\n",
    "        return\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Main Evaluation Script\n",
    "# ==============================================================================\n",
    "\n",
    "try:\n",
    "    print(f\"\\nLoading model for evaluation: {MODEL_TO_EVALUATE}\")\n",
    "    model = tf.keras.models.load_model(MODEL_TO_EVALUATE)\n",
    "    ground_truth_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    xml_files = [f for f in os.listdir(IDMT_XML_DIR) if f.endswith('.xml')]\n",
    "    print(f\"\\nFound {len(xml_files)} XML files. Starting event-level evaluation...\")\n",
    "\n",
    "    for xml_file in tqdm(xml_files, desc=\"Processing Files\"):\n",
    "        xml_path = os.path.join(IDMT_XML_DIR, xml_file)\n",
    "        audio_filename = xml_file.replace('.xml', '.wav')\n",
    "        audio_path = os.path.join(IDMT_AUDIO_DIR, audio_filename)\n",
    "        if not os.path.exists(audio_path): continue\n",
    "\n",
    "        # Load audio once per file\n",
    "        y_full, sr = librosa.load(audio_path, sr=None)\n",
    "        for note_event in parse_idmt_xml(xml_path):\n",
    "            technique_name = note_event['technique']\n",
    "            # Map ALL events to class or 'other'\n",
    "            ground_truth_index = IDMT_TO_MAGCIL_IDX.get(technique_name, OTHER_IDX)\n",
    "            start_sample = int(note_event['onset'] * sr)\n",
    "            end_sample = int(note_event['offset'] * sr)\n",
    "            note_audio_segment = y_full[start_sample:end_sample]\n",
    "            features = extract_features_from_segmented_audio(note_audio_segment, sr)\n",
    "            if features is not None:\n",
    "                features_batch = np.expand_dims(features, axis=0)\n",
    "                prediction_probs = model.predict(features_batch, verbose=0)\n",
    "                pred_idx = np.argmax(prediction_probs, axis=1)[0]\n",
    "                # If model predicts anything outside EVAL set, map to OTHER\n",
    "                if pred_idx not in EVAL_CLASS_INDICES[:-1]:  # Last is 'other'\n",
    "                    pred_idx = OTHER_IDX\n",
    "                ground_truth_labels.append(ground_truth_index)\n",
    "                predicted_labels.append(pred_idx)\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 3. Report Results\n",
    "    # ==============================================================================\n",
    "    print(\"\\n--- EVALUATION COMPLETE ---\")\n",
    "    if not ground_truth_labels:\n",
    "        print(\"‼️ No valid notes were found to evaluate. Check paths and the mapping.\")\n",
    "    else:\n",
    "        print(f\"Evaluated {len(ground_truth_labels)} note events.\")\n",
    "        print(f\"Overall Accuracy: {accuracy_score(ground_truth_labels, predicted_labels):.2%}\\n\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(\n",
    "            ground_truth_labels, predicted_labels, labels=EVAL_CLASS_INDICES, target_names=EVAL_CLASSES, zero_division=0))\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(ground_truth_labels, predicted_labels, labels=EVAL_CLASS_INDICES))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"=\"*60)\n",
    "    print(f\"‼️ ERROR: Model or Dataset Not Found! Check paths: '{MODEL_TO_EVALUATE}', '{IDMT_AUDIO_DIR}', '{IDMT_XML_DIR}'\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb03c5",
   "metadata": {},
   "source": [
    "### Final output is not great (shows severe distributional shift)\n",
    "\n",
    "| Technique         | Test Precision | Test Recall | Test F1  | Test Support | Train Precision | Train Recall | Train F1 | Train Support |\n",
    "|-------------------|:-------------:|:-----------:|:--------:|:------------:|:--------------:|:------------:|:--------:|:-------------:|\n",
    "| bend              | 0.01          | 0.57        | 0.02     | 54           | 1.00           | 1.00         | 1.00     | 9             |\n",
    "| slide             | 0.05          | 0.13        | 0.08     | 93           | 1.00           | 0.89         | 0.94     | 9             |\n",
    "| vibrato           | 0.00          | 0.00        | 0.00     | 117          | 1.00           | 1.00         | 1.00     | 9             |\n",
    "| alternate picking |                |             |          |              | 1.00           | 1.00         | 1.00     | 18            |\n",
    "| hammer on         |                |             |          |              | 0.73           | 0.89         | 0.80     | 9             |\n",
    "| legato            |                |             |          |              | 1.00           | 1.00         | 1.00     | 18            |\n",
    "| pull off          |                |             |          |              | 0.86           | 0.67         | 0.75     | 9             |\n",
    "| sweep picking     |                |             |          |              | 1.00           | 0.89         | 0.94     | 9             |\n",
    "| tapping           |                |             |          |              | 0.90           | 1.00         | 0.95     | 18            |\n",
    "| other             | 0.98           | 0.32        | 0.49     | 4013         |                |              |          |               |\n",
    "|-------------------|---------------|-------------|----------|--------------|----------------|--------------|----------|---------------|\n",
    "| accuracy          |               |             | 0.31     | 4277         |                |              | 0.94     | 108           |\n",
    "| macro avg         | 0.26           | 0.26        | 0.15     | 4277         | 0.94           | 0.93         | 0.93     | 108           |\n",
    "| weighted avg      | 0.92           | 0.31        | 0.46     | 4277         | 0.95           | 0.94         | 0.94     | 108           |\n",
    "| Macro F1          |                |             |          |              |                |              | 0.9311   |               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ba712",
   "metadata": {},
   "source": [
    "## B) Create a unified dataset (IDMT, AGPT, Magcil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672314f",
   "metadata": {},
   "source": [
    "### 1. magcil dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. Set the path to your original MAGCIL dataset\n",
    "MAGCIL_INPUT_DIR = \"\"\n",
    "\n",
    "# 2. Set the path for the new, reorganized dataset\n",
    "MAGCIL_OUTPUT_DIR = \"\" # Using a new name to avoid confusion\n",
    "\n",
    "# 3. Define the NEW mapping from original MAGCIL folder names to the new unified names.\n",
    "MAGCIL_TO_UNIFIED = {\n",
    "    # --- New Picking Classes (now separate) ---\n",
    "    'alternate picking': 'alternate_picking',\n",
    "    'sweep picking': 'sweep_picking',\n",
    "    \n",
    "    # --- Merged Legato Class ---\n",
    "    'hammer on': 'legato',\n",
    "    'pull off': 'legato',\n",
    "    'legato': 'legato',\n",
    "    \n",
    "    # --- Direct 1-to-1 Mappings for Primary Classes ---\n",
    "    'slide': 'slide',\n",
    "    'bend': 'bend',\n",
    "    'vibrato': 'vibrato',\n",
    "    'palm mute': 'palm_mute',\n",
    "    'staccato': 'staccato',\n",
    "    'harmonics': 'harmonics',\n",
    "    \n",
    "    # NOTE: Any folder in the source directory that is NOT a key in this dictionary\n",
    "    # (e.g., 'tapping') will be automatically placed in the 'other' folder.\n",
    "}\n",
    "\n",
    "# --- Main Processing Script ---\n",
    "\n",
    "print(f\"Reorganizing MAGCIL with new 11-class mapping into '{MAGCIL_OUTPUT_DIR}'\")\n",
    "\n",
    "# Start with a clean directory to ensure no old files remain\n",
    "if os.path.exists(MAGCIL_OUTPUT_DIR):\n",
    "    shutil.rmtree(MAGCIL_OUTPUT_DIR)\n",
    "os.makedirs(MAGCIL_OUTPUT_DIR)\n",
    "\n",
    "# Determine all unique destination folders from the mapping values\n",
    "unified_classes = set(MAGCIL_TO_UNIFIED.values())\n",
    "unified_classes.add('other')   # Add 'other' for any unmapped source folders\n",
    "\n",
    "# Create all necessary destination directories\n",
    "for class_name in unified_classes:\n",
    "    os.makedirs(os.path.join(MAGCIL_OUTPUT_DIR, class_name), exist_ok=True)\n",
    "\n",
    "try:\n",
    "    source_class_folders = [d for d in os.listdir(MAGCIL_INPUT_DIR) if os.path.isdir(os.path.join(MAGCIL_INPUT_DIR, d))]\n",
    "except FileNotFoundError:\n",
    "    print(f\"‼️ ERROR: Input directory not found at '{MAGCIL_INPUT_DIR}'. Please check the path.\")\n",
    "    source_class_folders = []\n",
    "\n",
    "print(f\"Found {len(source_class_folders)} source folders. Starting reorganization...\")\n",
    "\n",
    "# Iterate through each source folder and copy its files based on the mapping\n",
    "for source_folder in tqdm(source_class_folders, desc=\"Processing Classes\"):\n",
    "    \n",
    "    # Use .get() to look up the mapping. If a folder isn't in the map, default to 'other'.\n",
    "    unified_class = MAGCIL_TO_UNIFIED.get(source_folder, 'other')\n",
    "    \n",
    "    source_path = os.path.join(MAGCIL_INPUT_DIR, source_folder)\n",
    "    destination_path = os.path.join(MAGCIL_OUTPUT_DIR, unified_class)\n",
    "    \n",
    "    # Copy all .wav files from the source to the unified destination\n",
    "    for filename in os.listdir(source_path):\n",
    "        if filename.endswith('.wav'):\n",
    "            shutil.copy2(os.path.join(source_path, filename), os.path.join(destination_path, filename))\n",
    "\n",
    "if source_class_folders:\n",
    "    print(f\"\\n✅ Reorganization complete! The new dataset is ready at '{MAGCIL_OUTPUT_DIR}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f404153",
   "metadata": {},
   "source": [
    "### 2. IDMT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cebca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "IDMT_AUDIO_DIR = \"\"\n",
    "IDMT_XML_DIR = \"\"\n",
    "OUTPUT_DATA_DIR = \"\"\n",
    "FIXED_WINDOW_DURATION_SEC = 0.4 # Using the 400ms window as decided\n",
    "\n",
    "# --- NEW Unified Class Mappings for the 11-class structure ---\n",
    "\n",
    "# Mapping for <expressionStyle> tags.\n",
    "# NOTE: IDMT does not distinguish 'hammer on'/'pull off', so we don't have a 'legato' mapping here.\n",
    "# 'NO' is a special case to trigger the fallback to the excitation style.\n",
    "IDMT_EXPRESSION_TO_UNIFIED = {\n",
    "    'BE': 'bend',\n",
    "    'SL': 'slide',\n",
    "    'VI': 'vibrato',\n",
    "    'ST': 'staccato',\n",
    "    'HA': 'harmonics',\n",
    "    'NO': None,  # Special marker: If 'NO', check the excitation style instead.\n",
    "}\n",
    "\n",
    "# Mapping for <excitationStyle> tags.\n",
    "# This is ONLY used if the expressionStyle was 'NO'.\n",
    "# NOTE: IDMT does not distinguish 'alternate' vs 'sweep' picking. We map 'PK' to the general 'picking' class.\n",
    "IDMT_EXCITATION_TO_UNIFIED = {\n",
    "    'PK': 'picking',\n",
    "    'MU': 'palm_mute',\n",
    "}\n",
    "\n",
    "# --- Main Processing Script ---\n",
    "print(f\"Processing IDMT dataset for the new 11-class structure.\")\n",
    "print(f\"Output will be saved to '{OUTPUT_DATA_DIR}'\")\n",
    "\n",
    "# Start with a clean directory\n",
    "if os.path.exists(OUTPUT_DATA_DIR):\n",
    "    shutil.rmtree(OUTPUT_DATA_DIR)\n",
    "os.makedirs(OUTPUT_DATA_DIR)\n",
    "\n",
    "# Create directories for all possible unified classes, plus 'other'\n",
    "all_target_classes = set(IDMT_EXPRESSION_TO_UNIFIED.values()) | set(IDMT_EXCITATION_TO_UNIFIED.values())\n",
    "all_target_classes.discard(None)\n",
    "all_target_classes.add('other')\n",
    "# Manually add the classes that only exist in MAGCIL to ensure the folder structure is identical\n",
    "all_target_classes.update(['alternate_picking', 'sweep_picking', 'legato'])\n",
    "\n",
    "for unified_class in all_target_classes:\n",
    "    os.makedirs(os.path.join(OUTPUT_DATA_DIR, unified_class), exist_ok=True)\n",
    "\n",
    "# Main loop\n",
    "try:\n",
    "    xml_files = [f for f in os.listdir(IDMT_XML_DIR) if f.endswith('.xml')]\n",
    "    for xml_file in tqdm(xml_files, desc=\"Processing XML annotations\"):\n",
    "        audio_file = xml_file.replace('.xml', '.wav')\n",
    "        audio_path = os.path.join(IDMT_AUDIO_DIR, audio_file)\n",
    "        xml_path = os.path.join(IDMT_XML_DIR, xml_file)\n",
    "\n",
    "        if not os.path.exists(audio_path):\n",
    "            continue\n",
    "\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        \n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        event_idx = 0\n",
    "        for event in root.findall('.//event'):\n",
    "            expression_tag = event.find('expressionStyle')\n",
    "            excitation_tag = event.find('excitationStyle')\n",
    "\n",
    "            if expression_tag is None or excitation_tag is None:\n",
    "                continue\n",
    "\n",
    "            expression_code = expression_tag.text.strip().upper()\n",
    "            excitation_code = excitation_tag.text.strip().upper()\n",
    "            \n",
    "            unified_class = None\n",
    "            # Primary case: Check for a specific expressive technique\n",
    "            if expression_code != 'NO':\n",
    "                unified_class = IDMT_EXPRESSION_TO_UNIFIED.get(expression_code)\n",
    "                if unified_class is None: # It's an unmapped expressive technique\n",
    "                    unified_class = 'other'\n",
    "            # Fallback case: If expression is 'NO', check the excitation style\n",
    "            else:\n",
    "                unified_class = IDMT_EXCITATION_TO_UNIFIED.get(excitation_code)\n",
    "                if unified_class is None: # It's an unmapped excitation technique\n",
    "                    unified_class = 'other'\n",
    "\n",
    "            onset_sec = float(event.find('onsetSec').text)\n",
    "            offset_sec = float(event.find('offsetSec').text)\n",
    "\n",
    "            start_sample = int(onset_sec * sr)\n",
    "            end_sample = start_sample + int(FIXED_WINDOW_DURATION_SEC * sr)\n",
    "            end_sample = min(end_sample, len(y))\n",
    "            \n",
    "            segment = y[start_sample:end_sample]\n",
    "            \n",
    "            if len(segment) < 2048:\n",
    "                continue\n",
    "\n",
    "            fname = f\"{os.path.splitext(audio_file)[0]}_{event_idx}_{unified_class}.wav\"\n",
    "            event_idx += 1\n",
    "            \n",
    "            out_dir = os.path.join(OUTPUT_DATA_DIR, unified_class)\n",
    "            out_path = os.path.join(out_dir, fname)\n",
    "            sf.write(out_path, segment, sr)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‼️ ERROR: Could not find IDMT directories. Check paths for audio ('{IDMT_AUDIO_DIR}') and XML ('{IDMT_XML_DIR}').\")\n",
    "\n",
    "print(f\"\\n✅ All IDMT segments cropped and saved in file-level folders at '{OUTPUT_DATA_DIR}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ce1b1",
   "metadata": {},
   "source": [
    "### 3. AGPT dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b61e4",
   "metadata": {},
   "source": [
    "#### 3.1 quick check to find the median of duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a51e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick sanity-check for the duration of file-level annotations\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "# Use the path to your final, reorganized MAGCIL dataset\n",
    "MAGCIL_UNIFIED_DIR = \"\"\n",
    "\n",
    "# --- Step 1: Collect Durations for all Audio Files ---\n",
    "\n",
    "# We'll store durations in a dictionary to potentially analyze per-class stats later\n",
    "durations_by_class = {}\n",
    "all_durations = []\n",
    "\n",
    "try:\n",
    "    class_folders = [d for d in os.listdir(MAGCIL_UNIFIED_DIR) if os.path.isdir(os.path.join(MAGCIL_UNIFIED_DIR, d))]\n",
    "    \n",
    "    print(f\"Analyzing audio file durations in '{MAGCIL_UNIFIED_DIR}'...\")\n",
    "\n",
    "    for class_folder in tqdm(class_folders, desc=\"Scanning Classes\"):\n",
    "        class_path = os.path.join(MAGCIL_UNIFIED_DIR, class_folder)\n",
    "        durations_by_class[class_folder] = []\n",
    "        \n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    # librosa.get_duration is very fast as it only reads the file header\n",
    "                    duration = librosa.get_duration(path=file_path)\n",
    "                    durations_by_class[class_folder].append(duration)\n",
    "                    all_durations.append(duration)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not process file {file_path}. Error: {e}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‼️ ERROR: Directory not found at '{MAGCIL_UNIFIED_DIR}'. Please check the path.\")\n",
    "\n",
    "# --- Step 2: Calculate and Print Statistics ---\n",
    "\n",
    "if all_durations:\n",
    "    # Convert to a NumPy array for efficient calculations\n",
    "    all_durations = np.array(all_durations)\n",
    "    \n",
    "    print(\"\\n--- Overall Duration Statistics for MAGCIL Dataset ---\")\n",
    "    print(f\"Total Samples Analyzed: {len(all_durations)}\")\n",
    "    print(f\"Mean Duration:      {np.mean(all_durations):.3f} seconds\")\n",
    "    print(f\"Median Duration:    {np.median(all_durations):.3f} seconds\")\n",
    "    print(f\"Min Duration:       {np.min(all_durations):.3f} seconds\")\n",
    "    print(f\"Max Duration:       {np.max(all_durations):.3f} seconds\")\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"25th Percentile:    {np.percentile(all_durations, 25):.3f} seconds\")\n",
    "    print(f\"75th Percentile:    {np.percentile(all_durations, 75):.3f} seconds\")\n",
    "    print(f\"95th Percentile:    {np.percentile(all_durations, 95):.3f} seconds\")\n",
    "    \n",
    "    # --- Step 3: Plot the Distribution ---\n",
    "    \n",
    "    print(\"\\nGenerating duration histogram...\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    sns.histplot(all_durations, bins=50, kde=True, ax=ax)\n",
    "    \n",
    "    # Add vertical lines for mean and median\n",
    "    ax.axvline(np.mean(all_durations), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(all_durations):.2f}s')\n",
    "    ax.axvline(np.median(all_durations), color='green', linestyle='-', linewidth=2, label=f'Median: {np.median(all_durations):.2f}s')\n",
    "    \n",
    "    ax.set_title('Distribution of Audio File Durations in MAGCIL Dataset', fontsize=16)\n",
    "    ax.set_xlabel('Duration (seconds)', fontsize=12)\n",
    "    ax.set_ylabel('Number of Files', fontsize=12)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo audio files were found to analyze.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "# Use the path to your IDMT XML annotations\n",
    "IDMT_XML_DIR = \"\"\n",
    "\n",
    "# --- Step 1: Parse all XML files and collect event durations ---\n",
    "\n",
    "all_durations = []\n",
    "\n",
    "try:\n",
    "    xml_files = [f for f in os.listdir(IDMT_XML_DIR) if f.endswith('.xml')]\n",
    "    \n",
    "    print(f\"Analyzing note event durations from {len(xml_files)} XML files in '{IDMT_XML_DIR}'...\")\n",
    "\n",
    "    for xml_file in tqdm(xml_files, desc=\"Parsing XML Files\"):\n",
    "        xml_path = os.path.join(IDMT_XML_DIR, xml_file)\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            for event in root.findall('.//event'):\n",
    "                onset_tag = event.find('onsetSec')\n",
    "                offset_tag = event.find('offsetSec')\n",
    "                \n",
    "                # Ensure both tags exist to calculate a valid duration\n",
    "                if onset_tag is not None and offset_tag is not None:\n",
    "                    onset_sec = float(onset_tag.text)\n",
    "                    offset_sec = float(offset_tag.text)\n",
    "                    duration = offset_sec - onset_sec\n",
    "                    \n",
    "                    # Add a check for valid durations (e.g., non-negative)\n",
    "                    if duration > 0:\n",
    "                        all_durations.append(duration)\n",
    "\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"Warning: Could not parse file {xml_file}. Error: {e}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‼️ ERROR: Directory not found at '{IDMT_XML_DIR}'. Please check the path.\")\n",
    "\n",
    "# --- Step 2: Calculate and Print Statistics ---\n",
    "\n",
    "if all_durations:\n",
    "    all_durations = np.array(all_durations)\n",
    "    \n",
    "    print(\"\\n--- Note Event Duration Statistics for IDMT Dataset ---\")\n",
    "    print(f\"Total Note Events Analyzed: {len(all_durations)}\")\n",
    "    print(f\"Mean Duration:      {np.mean(all_durations):.3f} seconds\")\n",
    "    print(f\"Median Duration:    {np.median(all_durations):.3f} seconds\")\n",
    "    print(f\"Min Duration:       {np.min(all_durations):.3f} seconds\")\n",
    "    print(f\"Max Duration:       {np.max(all_durations):.3f} seconds\")\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"25th Percentile:    {np.percentile(all_durations, 25):.3f} seconds\")\n",
    "    print(f\"75th Percentile:    {np.percentile(all_durations, 75):.3f} seconds\")\n",
    "    print(f\"95th Percentile:    {np.percentile(all_durations, 95):.3f} seconds\")\n",
    "    \n",
    "    # --- Step 3: Plot the Distribution ---\n",
    "    \n",
    "    print(\"\\nGenerating duration histogram...\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # We might have a long tail, so let's focus the plot on the bulk of the data\n",
    "    # For example, plot only durations less than 2 seconds to see the details\n",
    "    plot_durations = all_durations[all_durations < 2]\n",
    "    sns.histplot(plot_durations, bins=50, kde=True, ax=ax)\n",
    "    \n",
    "    ax.axvline(np.mean(all_durations), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(all_durations):.2f}s')\n",
    "    ax.axvline(np.median(all_durations), color='green', linestyle='-', linewidth=2, label=f'Median: {np.median(all_durations):.2f}s')\n",
    "    \n",
    "    ax.set_title('Distribution of Note Event Durations in IDMT Dataset', fontsize=16)\n",
    "    ax.set_xlabel('Duration (seconds)', fontsize=12)\n",
    "    ax.set_ylabel('Number of Notes', fontsize=12)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo note events were found to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd349bfd",
   "metadata": {},
   "source": [
    "#### 3.2 AGPT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f70b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. Path to the root of the aGPTset dataset\n",
    "AGPT_ROOT_DIR = \"\"\n",
    "\n",
    "# 2. Path for the new, reorganized file-level dataset\n",
    "OUTPUT_DATA_DIR = \"\"\n",
    "\n",
    "# 3. Use the 400ms fixed window duration\n",
    "FIXED_WINDOW_DURATION_SEC = 0.4\n",
    "\n",
    "# --- Main Processing Script ---\n",
    "\n",
    "print(f\"Processing aGPTset from '{AGPT_ROOT_DIR}' for the 11-class structure.\")\n",
    "print(f\"Saving unified file-level data to '{OUTPUT_DATA_DIR}'\")\n",
    "\n",
    "# --- Step 1: Create the mapping from aGPT ID -> Unified Class Name ---\n",
    "\n",
    "# Load the CSV that maps technique IDs to their names\n",
    "techniques_csv_path = os.path.join(AGPT_ROOT_DIR, 'metadata', 'expressive_techniques.csv')\n",
    "techniques_df = pd.read_csv(techniques_csv_path)\n",
    "id_to_name = techniques_df.set_index('expressive_technique_id')['name'].to_dict()\n",
    "\n",
    "# Define the NEW mapping from the aGPT technique names to YOUR 11 unified class names\n",
    "agpt_name_to_unified = {\n",
    "    'Bending': 'bend',\n",
    "    'Hammer-on': 'legato', # aGPT 'Hammer-on' maps to the unified 'legato' class\n",
    "    'Staccato': 'staccato',\n",
    "    'Vibrato': 'vibrato',\n",
    "    'Palm Mute': 'palm_mute',\n",
    "    'Natural Harmonics': 'harmonics',\n",
    "    'Pick Near Bridge': 'picking',      # aGPT picking types map to the general 'picking' class\n",
    "    'Pick Over the Soundhole': 'picking',\n",
    "    # All percussive techniques like 'Kick', 'Snare-A/B', 'Tom' are not in this map,\n",
    "    # so they will automatically be classified as 'other'.\n",
    "}\n",
    "\n",
    "# Combine the two maps to get a final ID -> Unified Class mapping\n",
    "AGPT_ID_TO_UNIFIED = {}\n",
    "for tech_id, tech_name in id_to_name.items():\n",
    "    AGPT_ID_TO_UNIFIED[tech_id] = agpt_name_to_unified.get(tech_name, 'other')\n",
    "\n",
    "print(\"\\nFinal mapping from aGPT ID to Unified Class:\")\n",
    "print(AGPT_ID_TO_UNIFIED)\n",
    "\n",
    "# --- Step 2: Create all necessary output directories ---\n",
    "\n",
    "# Start with a clean directory\n",
    "if os.path.exists(OUTPUT_DATA_DIR):\n",
    "    shutil.rmtree(OUTPUT_DATA_DIR)\n",
    "os.makedirs(OUTPUT_DATA_DIR)\n",
    "\n",
    "# Explicitly define all 11 target classes to ensure identical folder structure\n",
    "all_unified_classes = [\n",
    "    'picking', 'sweep_picking', 'alternate_picking', 'legato', 'slide',\n",
    "    'bend', 'vibrato', 'palm_mute', 'staccato', 'harmonics', 'other'\n",
    "]\n",
    "\n",
    "for unified_class in all_unified_classes:\n",
    "    os.makedirs(os.path.join(OUTPUT_DATA_DIR, unified_class), exist_ok=True)\n",
    "\n",
    "# --- Step 3: Process the main note labels CSV ---\n",
    "note_labels_csv_path = os.path.join(AGPT_ROOT_DIR, 'metadata', 'note_labels.csv')\n",
    "notes_df = pd.read_csv(note_labels_csv_path)\n",
    "audio_cache = {}\n",
    "\n",
    "print(f\"\\nProcessing {len(notes_df)} labeled notes from 'note_labels.csv'...\")\n",
    "\n",
    "for index, row in tqdm(notes_df.iterrows(), total=len(notes_df), desc=\"Processing Notes\"):\n",
    "    audio_filename = row['audio_file_path']\n",
    "    full_audio_path = os.path.join(AGPT_ROOT_DIR, 'data', 'audio', audio_filename)\n",
    "    \n",
    "    technique_id = row['expressive_technique_id']\n",
    "    unified_class = AGPT_ID_TO_UNIFIED.get(technique_id, 'other')\n",
    "\n",
    "    if audio_filename not in audio_cache:\n",
    "        if not os.path.exists(full_audio_path):\n",
    "            continue\n",
    "        try:\n",
    "            y, sr = librosa.load(full_audio_path, sr=None)\n",
    "            audio_cache[audio_filename] = (y, sr)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {audio_filename}: {e}\")\n",
    "            audio_cache[audio_filename] = (None, None)\n",
    "            continue\n",
    "    \n",
    "    y, sr = audio_cache[audio_filename]\n",
    "    if y is None:\n",
    "        continue\n",
    "    \n",
    "    onset_sec = row['onset_label_seconds']\n",
    "    start_sample = int(onset_sec * sr)\n",
    "    end_sample = start_sample + int(FIXED_WINDOW_DURATION_SEC * sr)\n",
    "    end_sample = min(end_sample, len(y))\n",
    "    \n",
    "    segment = y[start_sample:end_sample]\n",
    "    \n",
    "    if len(segment) < 2048:\n",
    "        continue\n",
    "        \n",
    "    base_name = os.path.splitext(audio_filename)[0]\n",
    "    new_fname = f\"{base_name}_note{index}_{unified_class}.wav\"\n",
    "    \n",
    "    out_dir = os.path.join(OUTPUT_DATA_DIR, unified_class)\n",
    "    out_path = os.path.join(out_dir, new_fname)\n",
    "    \n",
    "    try:\n",
    "        sf.write(out_path, segment, sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing segment for {new_fname}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ All labeled aGPTset notes have been cropped and saved to '{OUTPUT_DATA_DIR}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277f08a",
   "metadata": {},
   "source": [
    "### 4. Visualize class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a30166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "# Point this to the dataset directory you want to analyze.\n",
    "# For example:\n",
    "DATASET_DIR = \"\"\n",
    "\n",
    "# --- Step 1: Count Samples in Each Class Folder ---\n",
    "\n",
    "class_counts = {}\n",
    "\n",
    "try:\n",
    "    # Get all items in the directory that are folders\n",
    "    class_folders = [d for d in os.listdir(DATASET_DIR) if os.path.isdir(os.path.join(DATASET_DIR, d))]\n",
    "    \n",
    "    print(f\"Analyzing class distribution in: '{DATASET_DIR}'\\n\")\n",
    "\n",
    "    for class_folder in tqdm(class_folders, desc=\"Scanning folders\"):\n",
    "        class_path = os.path.join(DATASET_DIR, class_folder)\n",
    "        # Count only the .wav files in each folder\n",
    "        num_files = len([f for f in os.listdir(class_path) if f.endswith('.wav')])\n",
    "        class_counts[class_folder] = num_files\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‼️ ERROR: Directory not found at '{DATASET_DIR}'. Please check the path.\")\n",
    "    class_counts = {}\n",
    "\n",
    "# --- Step 2: Print a Summary Table ---\n",
    "\n",
    "if class_counts:\n",
    "    # Convert to a Pandas DataFrame for easy sorting and printing\n",
    "    df_counts = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count'])\n",
    "    df_counts = df_counts.sort_values('Count', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"--- Class Distribution Summary ---\")\n",
    "    print(df_counts)\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total Samples: {df_counts['Count'].sum()}\")\n",
    "    \n",
    "    # --- Step 3: Generate the Bar Chart Visualization ---\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    # Create the bar plot using the sorted DataFrame\n",
    "    sns.barplot(x='Class', y='Count', data=df_counts, ax=ax, palette='viridis')\n",
    "    \n",
    "    # Add the exact count on top of each bar for clarity\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{int(p.get_height())}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='center', \n",
    "                    xytext=(0, 9), \n",
    "                    textcoords='offset points')\n",
    "\n",
    "    # Formatting the plot\n",
    "    dataset_name = os.path.basename(DATASET_DIR)\n",
    "    ax.set_title(f'Class Distribution for {dataset_name}', fontsize=18, weight='bold')\n",
    "    ax.set_xlabel('Technique Class', fontsize=12)\n",
    "    ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right') # Rotate labels to prevent overlap\n",
    "    plt.tight_layout() # Adjust layout to make sure everything fits\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo classes found or directory is empty. Cannot generate visualization.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630513b",
   "metadata": {},
   "source": [
    "### 5. train-test split for IDMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e437ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. Path to your source dataset\n",
    "DATA_ROOT = \"\"\n",
    "\n",
    "# 2. Path for the new directory where the splits will be saved\n",
    "OUTPUT_DIR = \"\"\n",
    "\n",
    "# --- Step 1: Discover Classes and Perform Logical Split ---\n",
    "\n",
    "print(\"--- Step 1: Performing logical 80/20 split for each class ---\")\n",
    "\n",
    "# FIX: Get the class names DIRECTLY from the DATA_ROOT directory.\n",
    "# This ensures we are working with the correct folder names for the IDMT dataset.\n",
    "try:\n",
    "    idmt_classes = [d for d in os.listdir(DATA_ROOT) if os.path.isdir(os.path.join(DATA_ROOT, d))]\n",
    "    print(f\"Found {len(idmt_classes)} classes in '{DATA_ROOT}': {idmt_classes}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‼️ ERROR: Source directory not found at '{DATA_ROOT}'. Please check the path.\")\n",
    "    idmt_classes = []\n",
    "\n",
    "# Now, use the correct 'idmt_classes' list to find the files\n",
    "segments_by_class = {lab: sorted(glob.glob(f\"{DATA_ROOT}/{lab}/*.wav\")) for lab in idmt_classes}\n",
    "\n",
    "train_files = []\n",
    "test_files = []\n",
    "test_fraction = 0.8  # 80% test set\n",
    "\n",
    "for lab, files in segments_by_class.items():\n",
    "    if len(files) > 1:\n",
    "        train, test = train_test_split(files, test_size=test_fraction, random_state=42)\n",
    "        train_files.extend(train)\n",
    "        test_files.extend(test)\n",
    "    elif len(files) == 1:\n",
    "        train_files.extend(files)\n",
    "        print(f\"Warning: Class '{lab}' has only one sample. Adding it to the training set.\")\n",
    "    else:\n",
    "        print(f\"Warning: Class '{lab}' has no samples. Skipping.\")\n",
    "\n",
    "# Calculate the total number of files found and processed\n",
    "total_files_found = len(train_files) + len(test_files)\n",
    "\n",
    "print(f\"\\nLogical split complete:\")\n",
    "print(f\" - Total files processed: {total_files_found}\") # This should now be 4000+\n",
    "print(f\" - {len(train_files)} files designated for training (20%).\")\n",
    "print(f\" - {len(test_files)} files designated for testing (80%).\")\n",
    "\n",
    "\n",
    "# --- Step 2: Physically Copy Files into New Train/Test Folders ---\n",
    "\n",
    "# (This part of the code was already correct and needs no changes)\n",
    "print(f\"\\n--- Step 2: Copying files into new directory structure at '{OUTPUT_DIR}' ---\")\n",
    "\n",
    "def copy_files_to_split_dir(file_list, split_name, base_output_dir):\n",
    "    split_dir = os.path.join(base_output_dir, split_name)\n",
    "    for file_path in tqdm(file_list, desc=f\"Copying {split_name} files\"):\n",
    "        class_name = os.path.basename(os.path.dirname(file_path))\n",
    "        class_dir = os.path.join(split_dir, class_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        shutil.copy2(file_path, class_dir)\n",
    "\n",
    "if total_files_found > 0:\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    \n",
    "    copy_files_to_split_dir(train_files, 'train', OUTPUT_DIR)\n",
    "    copy_files_to_split_dir(test_files, 'test', OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"\\n✅ Physical split complete! Your data is now organized in '{OUTPUT_DIR}'.\")\n",
    "else:\n",
    "    print(\"\\nNo files were processed. Cannot create split directories.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f967ca2",
   "metadata": {},
   "source": [
    "### 6. Combine the datasets (train: AGPT, Magcil, IDMT-train, test: IDMT-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d650596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration: Define all source and destination paths ---\n",
    "\n",
    "# 1. Source Directories\n",
    "MAGCIL_DIR = \"\"\n",
    "AGPT_DIR = \"\"\n",
    "IDMT_SPLIT_DIR = \"\"\n",
    "\n",
    "# 2. Final Output Directory\n",
    "COMBINED_OUTPUT_DIR = \"\"\n",
    "\n",
    "# --- Main Merging Script ---\n",
    "\n",
    "# A helper function to make the copying process clean and reusable\n",
    "def merge_dataset(source_dir, dest_dir, dataset_name=\"\"):\n",
    "    \"\"\"\n",
    "    Copies all class folders and .wav files from a source to a destination.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"⚠️ Warning: Source directory not found, skipping: {source_dir}\")\n",
    "        return 0\n",
    "    \n",
    "    class_folders = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n",
    "    \n",
    "    file_copy_count = 0\n",
    "    for class_folder in tqdm(class_folders, desc=f\"Merging {dataset_name} - {os.path.basename(source_dir)}\"):\n",
    "        # --- MODIFICATION TO DROP STACCATO CLASS ---\n",
    "        if class_folder == 'staccato':\n",
    "            print(f\"Skipping class: {class_folder}\")\n",
    "            continue # This will skip the 'staccato' folder and not copy it.\n",
    "\n",
    "        source_class_path = os.path.join(source_dir, class_folder)\n",
    "        dest_class_path = os.path.join(dest_dir, class_folder)\n",
    "        \n",
    "        # Create the destination class folder if it doesn't exist\n",
    "        os.makedirs(dest_class_path, exist_ok=True)\n",
    "        \n",
    "        # Copy all .wav files\n",
    "        for filename in os.listdir(source_class_path):\n",
    "            if filename.endswith('.wav'):\n",
    "                shutil.copy2(os.path.join(source_class_path, filename), dest_class_path)\n",
    "                file_copy_count += 1\n",
    "    return file_copy_count\n",
    "\n",
    "\n",
    "print(f\"--- Starting dataset merge into '{COMBINED_OUTPUT_DIR}' ---\")\n",
    "\n",
    "# Start with a clean slate for the output directory\n",
    "if os.path.exists(COMBINED_OUTPUT_DIR):\n",
    "    print(f\"Removing existing directory: {COMBINED_OUTPUT_DIR}\")\n",
    "    shutil.rmtree(COMBINED_OUTPUT_DIR)\n",
    "\n",
    "# Create the main train and test directories\n",
    "train_dir = os.path.join(COMBINED_OUTPUT_DIR, 'train')\n",
    "test_dir = os.path.join(COMBINED_OUTPUT_DIR, 'test')\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(test_dir)\n",
    "\n",
    "# --- Step 1: Combine all training data ---\n",
    "print(\"\\n--- Merging TRAINING sets ---\")\n",
    "idmt_train_dir = os.path.join(IDMT_SPLIT_DIR, 'train')\n",
    "\n",
    "merge_dataset(MAGCIL_DIR, train_dir, \"MAGCIL\")\n",
    "merge_dataset(AGPT_DIR, train_dir, \"aGPTset\")\n",
    "merge_dataset(idmt_train_dir, train_dir, \"IDMT-Train\")\n",
    "\n",
    "# --- Step 2: Add the test data ---\n",
    "print(\"\\n--- Merging TESTING set ---\")\n",
    "idmt_test_dir = os.path.join(IDMT_SPLIT_DIR, 'test')\n",
    "merge_dataset(idmt_test_dir, test_dir, \"IDMT-Test\")\n",
    "\n",
    "# --- Step 3: Final Verification and Summary ---\n",
    "def count_files(directory):\n",
    "    total = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total += len([f for f in files if f.endswith('.wav')])\n",
    "    return total\n",
    "\n",
    "print(\"\\n--- Merge Complete! ---\")\n",
    "total_train_files = count_files(train_dir)\n",
    "total_test_files = count_files(test_dir)\n",
    "\n",
    "print(f\"Total training files: {total_train_files}\")\n",
    "print(f\"Total testing files:  {total_test_files}\")\n",
    "print(f\"✅ Your final combined dataset is ready at: '{COMBINED_OUTPUT_DIR}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8aa945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "# Point this to the root of your final combined dataset\n",
    "COMBINED_DATASET_ROOT = '/data/hjpark/combined_dataset_final'\n",
    "TRAIN_DIR = os.path.join(COMBINED_DATASET_ROOT, 'train')\n",
    "TEST_DIR = os.path.join(COMBINED_DATASET_ROOT, 'test')\n",
    "\n",
    "def analyze_and_visualize(dataset_dir, plot_title, output_filename):\n",
    "    \"\"\"\n",
    "    Scans a dataset directory, counts samples per class, prints a summary,\n",
    "    and saves a bar chart visualization.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Analyzing Class Distribution in: '{dataset_dir}' ---\")\n",
    "    \n",
    "    class_counts = {}\n",
    "    try:\n",
    "        class_folders = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])\n",
    "        if not class_folders:\n",
    "            print(\"‼️ ERROR: No class subdirectories found.\")\n",
    "            return\n",
    "\n",
    "        for class_folder in class_folders:\n",
    "            class_path = os.path.join(dataset_dir, class_folder)\n",
    "            num_files = len([f for f in os.listdir(class_path) if f.endswith('.wav')])\n",
    "            class_counts[class_folder] = num_files\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‼️ ERROR: Directory not found at '{dataset_dir}'. Please run the merge script first.\")\n",
    "        return\n",
    "\n",
    "    if not class_counts:\n",
    "        print(\"No .wav files found to analyze.\")\n",
    "        return\n",
    "\n",
    "    df_counts = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count'])\n",
    "    df_counts = df_counts.sort_values('Count', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n--- {plot_title} ---\")\n",
    "    print(df_counts.to_string())\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"Total Samples: {df_counts['Count'].sum()}\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # --- Generate the Bar Chart ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    sns.barplot(x='Class', y='Count', data=df_counts, ax=ax, palette='viridis')\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{int(p.get_height())}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='center', xytext=(0, 9), textcoords='offset points')\n",
    "\n",
    "    ax.set_title(plot_title, fontsize=18, weight='bold')\n",
    "    ax.set_xlabel('Unified Technique Class', fontsize=12)\n",
    "    ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(output_filename)\n",
    "    print(f\"✅ Chart saved to '{output_filename}'\")\n",
    "    plt.close() # Close the figure to free up memory\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Analyze and plot the training set\n",
    "    analyze_and_visualize(TRAIN_DIR, 'Final Training Set Distribution', 'combined_train_distribution.png')\n",
    "    \n",
    "    # Analyze and plot the testing set\n",
    "    analyze_and_visualize(TEST_DIR, 'Final Testing Set Distribution', 'combined_test_distribution.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e1ea20",
   "metadata": {},
   "source": [
    "## C) Train on the Unified dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de88e4",
   "metadata": {},
   "source": [
    "### Let's fine-tune the model by training on dataset 1 of IDMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c62658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Feature Extraction and Model Definition\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_features_from_audio(file_path):\n",
    "    \"\"\"\n",
    "    Extracts a 180-dimensional feature vector from a single audio file.\n",
    "    (This must be identical to the function used to create the dataset).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, mono=True)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        mfccs_mean, mfccs_std = np.mean(mfccs, axis=1), np.std(mfccs, axis=1)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40)\n",
    "        mel_spec_mean, mel_spec_std = np.mean(mel_spec, axis=1), np.std(mel_spec, axis=1)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=10)\n",
    "        chroma_mean, chroma_std = np.mean(chroma, axis=1), np.std(chroma, axis=1)\n",
    "        return np.concatenate([mfccs_mean, mfccs_std, mel_spec_mean, mel_spec_std, chroma_mean, chroma_std])\n",
    "    except Exception as e:\n",
    "        # print(f\"Error processing {file_path}: {e}\") # Uncomment for debugging\n",
    "        return None\n",
    "\n",
    "def create_model_A(input_shape=(180,), num_classes=10, dropout_rate=0.4, l2_lambda=1e-4):\n",
    "    \"\"\"\n",
    "    Creates and compiles the Keras model with Dropout and L2 regularization.\n",
    "    (CORRECTED: The final Dense layer is now correctly placed outside the loop).\n",
    "    \"\"\"\n",
    "    model = Sequential(name=\"Final_Combined_Model\")\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    # Four hidden layers\n",
    "    for _ in range(4):\n",
    "        model.add(Dense(800, activation='relu', kernel_regularizer=l2(l2_lambda)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    # Final output layer (placed correctly AFTER the loop)\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Data Loading from the Combined Train/Test Directories\n",
    "# ==============================================================================\n",
    "\n",
    "def load_data_from_final_dir(directory, label_map):\n",
    "    \"\"\"\n",
    "    Loads pre-processed audio files, extracts features, and returns X, y arrays.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for class_name, class_idx in label_map.items():\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"Warning: Class folder not found in {os.path.basename(directory)} set: {class_name}\")\n",
    "            continue\n",
    "        \n",
    "        wav_files = glob.glob(os.path.join(class_path, '*.wav'))\n",
    "        for file_path in tqdm(wav_files, desc=f\"Loading {class_name} ({os.path.basename(directory)})\"):\n",
    "            features = extract_features_from_audio(file_path)\n",
    "            if features is not None:\n",
    "                X.append(features)\n",
    "                y.append(class_idx)\n",
    "    return np.array(X), np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "TRAIN_DIR = '/data/hjpark/combined_dataset_augmented/train'\n",
    "TEST_DIR = '/data/hjpark/combined_dataset_final/test'\n",
    "MODEL_OUTPUT_DIR = 'models_final'\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Load Data ---\n",
    "# Discover class labels from the training directory subfolders\n",
    "try:\n",
    "    all_labels = sorted([d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))])\n",
    "    label_map = {name: i for i, name in enumerate(all_labels)}\n",
    "    num_classes = len(all_labels)\n",
    "    print(f\"Discovered {num_classes} classes: {all_labels}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‼️ ERROR: Training directory not found at '{TRAIN_DIR}'. Cannot proceed.\")\n",
    "    all_labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a92f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_labels:\n",
    "    X_train, y_train = load_data_from_final_dir(TRAIN_DIR, label_map)\n",
    "    X_test, y_test = load_data_from_final_dir(TEST_DIR, label_map)\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    print(\"Saving processed data to disk...\")\n",
    "    # np.save('X_train_final.npy', X_train)\n",
    "    # np.save('y_train_final.npy', y_train)\n",
    "    # np.save('X_test_final.npy', X_test)\n",
    "    # np.save('y_test_final.npy', y_test)\n",
    "    print(\"Data saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7d0fd",
   "metadata": {},
   "source": [
    "#### Side quest: Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d18a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# You may need to install this library: pip install audiomentations\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift\n",
    "\n",
    "# --- Configuration ---\n",
    "# The root of your final, combined training data\n",
    "SOURCE_TRAIN_DIR = '/data/hjpark/combined_dataset_final/train'\n",
    "\n",
    "# A new directory to save the augmented data to\n",
    "AUGMENTED_TRAIN_DIR = '/data/hjpark/combined_dataset_augmented/train'\n",
    "\n",
    "# Define which classes to augment and by how much\n",
    "# The number is the desired number of SAMPLES in that class folder\n",
    "AUGMENTATION_TARGETS = {\n",
    "    \"alternate_picking\": 2000,\n",
    "    \"bend\": 2000,\n",
    "    \"sweep_picking\": 2000,\n",
    "    \"slide\": 2000,\n",
    "    \"vibrato\": 2000,\n",
    "    \"harmonics\": 2000,\n",
    "    \"legato\": 2000,\n",
    "    # We can also slightly augment 'other' and 'palm_mute' if needed\n",
    "    \"other\": 10000, # Let's not make it too big\n",
    "    \"palm_mute\": 8000,\n",
    "    # 'picking' is already large, so we don't need to augment it\n",
    "    \"picking\": 0 \n",
    "}\n",
    "\n",
    "# Define the augmentation effects\n",
    "augmenter = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
    "])\n",
    "\n",
    "def augment_class_data():\n",
    "    \"\"\"\n",
    "    Applies audio augmentation to classes that are under-represented.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(SOURCE_TRAIN_DIR):\n",
    "        print(f\"ERROR: Source directory not found at {SOURCE_TRAIN_DIR}\")\n",
    "        return\n",
    "\n",
    "    # First, copy all original files to the new directory\n",
    "    print(f\"Copying original training data to {AUGMENTED_TRAIN_DIR}...\")\n",
    "    shutil.copytree(SOURCE_TRAIN_DIR, AUGMENTED_TRAIN_DIR)\n",
    "    \n",
    "    print(\"\\n--- Starting Augmentation ---\")\n",
    "    for class_name, target_count in AUGMENTATION_TARGETS.items():\n",
    "        class_dir = os.path.join(AUGMENTED_TRAIN_DIR, class_name)\n",
    "        if not os.path.exists(class_dir):\n",
    "            print(f\"Warning: Class folder '{class_name}' not found. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        original_files = [f for f in os.listdir(class_dir) if f.endswith('.wav')]\n",
    "        num_to_create = target_count - len(original_files)\n",
    "\n",
    "        if num_to_create <= 0:\n",
    "            print(f\"'{class_name}' already has enough samples. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Augmenting '{class_name}': Creating {num_to_create} new samples...\")\n",
    "        \n",
    "        for i in tqdm(range(num_to_create)):\n",
    "            # Pick a random original file to augment\n",
    "            random_file = np.random.choice(original_files)\n",
    "            file_path = os.path.join(class_dir, random_file)\n",
    "            \n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "            \n",
    "            # Apply a random augmentation from the 'augmenter' composition\n",
    "            augmented_audio = augmenter(samples=y, sample_rate=sr)\n",
    "            \n",
    "            # Save the new file\n",
    "            new_filename = f\"aug_{i}_{random_file}\"\n",
    "            output_path = os.path.join(class_dir, new_filename)\n",
    "            sf.write(output_path, augmented_audio, sr)\n",
    "\n",
    "    print(\"\\n✅ Augmentation complete!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    augment_class_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a127496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly check the class distribution after data augmentation step\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "# Point this to the training set directory that contains the augmented data\n",
    "AUGMENTED_DATASET_DIR = '/data/hjpark/combined_dataset_augmented/train'\n",
    "\n",
    "def visualize_augmented_distribution():\n",
    "    \"\"\"\n",
    "    Scans the augmented dataset directory, counts the samples per class,\n",
    "    and generates a summary table and a bar chart visualization.\n",
    "    \"\"\"\n",
    "    print(f\"--- Analyzing Class Distribution in: '{AUGMENTED_DATASET_DIR}' ---\")\n",
    "    \n",
    "    # --- Step 1: Count Samples in Each Class Folder ---\n",
    "    class_counts = {}\n",
    "    try:\n",
    "        class_folders = [d for d in os.listdir(AUGMENTED_DATASET_DIR) if os.path.isdir(os.path.join(AUGMENTED_DATASET_DIR, d))]\n",
    "        if not class_folders:\n",
    "            print(f\"‼️ ERROR: No class subdirectories found in '{AUGMENTED_DATASET_DIR}'.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Found {len(class_folders)} class folders. Counting samples...\")\n",
    "        for class_folder in tqdm(class_folders, desc=\"Scanning folders\"):\n",
    "            class_path = os.path.join(AUGMENTED_DATASET_DIR, class_folder)\n",
    "            num_files = len([f for f in os.listdir(class_path) if f.endswith('.wav')])\n",
    "            class_counts[class_folder] = num_files\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‼️ ERROR: Directory not found at '{AUGMENTED_DATASET_DIR}'. Please run the augmentation script first.\")\n",
    "        return\n",
    "\n",
    "    # --- Step 2: Print a Summary Table ---\n",
    "    if not class_counts:\n",
    "        print(\"No .wav files found to analyze.\")\n",
    "        return\n",
    "\n",
    "    df_counts = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count'])\n",
    "    df_counts = df_counts.sort_values('Count', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n--- Augmented Training Set Distribution ---\")\n",
    "    print(df_counts.to_string())\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total Augmented Training Samples: {df_counts['Count'].sum()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # --- Step 3: Generate the Bar Chart Visualization ---\n",
    "    print(\"\\nGenerating bar chart...\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    sns.barplot(x='Class', y='Count', data=df_counts, ax=ax, palette='viridis')\n",
    "    \n",
    "    # Add the exact count on top of each bar for clarity\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{int(p.get_height())}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='center', \n",
    "                    xytext=(0, 9), \n",
    "                    textcoords='offset points')\n",
    "\n",
    "    ax.set_title('Class Distribution for Augmented Training Set', fontsize=18, weight='bold')\n",
    "    ax.set_xlabel('Unified Technique Class', fontsize=12)\n",
    "    ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot to a file\n",
    "    output_filename = 'augmented_train_distribution.png'\n",
    "    plt.savefig(output_filename)\n",
    "    print(f\"\\n✅ Chart saved to '{output_filename}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    visualize_augmented_distribution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbf48d",
   "metadata": {},
   "source": [
    "### Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c643b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f47870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all_labels:\n",
    "#     import numpy as np\n",
    "\n",
    "#     print(\"Loading pre-processed data from disk...\")\n",
    "#     X_train = np.load('X_train_final.npy')\n",
    "#     y_train = np.load('y_train_final.npy')\n",
    "#     X_test = np.load('X_test_final.npy')\n",
    "#     y_test = np.load('y_test_final.npy')\n",
    "#     print(\"Data loaded successfully.\")\n",
    "\n",
    "#     print(\"\\n--- Data Loading Summary ---\")\n",
    "#     print(f\"Training samples: {len(X_train)}\")\n",
    "#     print(f\"Testing samples:  {len(X_test)}\")\n",
    "\n",
    "#     # ==============================================================================\n",
    "#     # 3. Model Training and Evaluation\n",
    "#     # ==============================================================================\n",
    "\n",
    "#     # --- Prepare Labels (One-Hot Encoding) ---\n",
    "#     y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "#     y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "#     # --- Instantiate the Model ---\n",
    "#     model = create_model_A(num_classes=num_classes, dropout_rate=0.5, l2_lambda=1e-3)\n",
    "#     model.summary()\n",
    "\n",
    "#     # --- Callbacks ---\n",
    "#     MODEL_SAVE_PATH = os.path.join(MODEL_OUTPUT_DIR, 'best_final_model.h5')\n",
    "#     checkpoint_callback = ModelCheckpoint(filepath=MODEL_SAVE_PATH, monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "#     early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "#     # --- Train the Model ---\n",
    "#     print(\"\\n--- Starting Final Model Training ---\")\n",
    "#     history = model.fit(\n",
    "#         X_train, y_train_cat,\n",
    "#         batch_size=32,  # <--- REDUCED FROM 64 to 32\n",
    "#         epochs=100,\n",
    "#         validation_data=(X_test, y_test_cat),\n",
    "#         callbacks=[checkpoint_callback, early_stopping_callback]\n",
    "#     )\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Model Training with Enhancements\n",
    "# ==============================================================================\n",
    "if all_labels:\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from sklearn.utils import class_weight\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "    print(\"Loading pre-processed AUGMENTED data from disk...\")\n",
    "    # --- CHANGE: Load the augmented training data ---\n",
    "    X_train = np.load('X_train_final.npy')\n",
    "    y_train = np.load('y_train_final.npy')\n",
    "    \n",
    "    # Test data remains the original\n",
    "    X_test = np.load('X_test_final.npy')\n",
    "    y_test = np.load('y_test_final.npy')\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    print(\"\\n--- Data Loading Summary ---\")\n",
    "    print(f\"Augmented training samples: {len(X_train)}\")\n",
    "    print(f\"Testing samples:  {len(X_test)}\")\n",
    "\n",
    "    # --- Prepare Labels (One-Hot Encoding) ---\n",
    "    y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    # --- NEW: Compute Class Weights ---\n",
    "    # This will create weights that are inversely proportional to class frequencies\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(\"\\nComputed Class Weights to counter imbalance.\")\n",
    "\n",
    "    # --- Instantiate the Model ---\n",
    "    # The dropout and L2 values are already strong, no change needed there.\n",
    "    model = create_model_A(num_classes=num_classes, dropout_rate=0.5, l2_lambda=1e-3)\n",
    "\n",
    "    # --- NEW: Compile model with a lower learning rate ---\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    # --- Callbacks ---\n",
    "    MODEL_SAVE_PATH = os.path.join(MODEL_OUTPUT_DIR, 'best_final_model_augmented.h5') # New model name\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=MODEL_SAVE_PATH, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    \n",
    "    # CHANGE: Increased patience for early stopping\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=25, verbose=1, restore_best_weights=True)\n",
    "    \n",
    "    # NEW: Learning Rate Scheduler\n",
    "    lr_scheduler_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, verbose=1, min_lr=1e-6)\n",
    "\n",
    "    # --- Train the Model ---\n",
    "    print(\"\\n--- Starting Final Model Training with Enhancements ---\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train_cat,\n",
    "        batch_size=32,\n",
    "        epochs=1000,\n",
    "        validation_data=(X_test, y_test_cat),\n",
    "        class_weight=class_weight_dict, # <-- Apply the class weights\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, lr_scheduler_callback] # <-- Add the new scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 1. Setup ---\n",
    "# Your trained model makes predictions on the IDMT test data\n",
    "y_pred_probabilities = model.predict(X_test)\n",
    "y_pred_from_model = np.argmax(y_pred_probabilities, axis=1)\n",
    "# This might be an array like: [0, 5, 2, 10, 3, 7, 1, 9 \n",
    "# Note the presence of 1, 2, 3 which are not in the IDMT ground truth.\n",
    "\n",
    "# The ground truth labels for your IDMT test set\n",
    "y_true_idmt = np.load('y_test_final.npy') # e.g. [0, 5, 4, 10, 6, 7, 0, 9\n",
    "\n",
    "# --- 2. Define the remapping rules ---\n",
    "# The set of classes that exist in the IDMT test set\n",
    "allowed_idmt_classes = {0, 4, 5, 6, 7, 8, 9, 10} \n",
    "other_class_index = 10\n",
    "\n",
    "# --- 3. Apply the remapping ---\n",
    "y_pred_remapped = []\n",
    "for pred in y_pred_from_model:\n",
    "    if pred in allowed_idmt_classes:\n",
    "        y_pred_remapped.append(pred)  # Keep the prediction\n",
    "    else:\n",
    "        y_pred_remapped.append(other_class_index) # Remap to \"other\"\n",
    "\n",
    "# Convert to numpy array\n",
    "y_pred_remapped = np.array(y_pred_remapped)\n",
    "\n",
    "# The remapped array would now look like: [0, 5, 10, 10, 10, 7, 10, 9]\n",
    "\n",
    "# --- 4. Evaluate ---\n",
    "# Now you can fairly compare the remapped predictions to the true labels\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_true_idmt, y_pred_remapped))\n",
    "print(confusion_matrix(y_true_idmt, y_pred_remapped))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf9e0b",
   "metadata": {},
   "source": [
    "### Test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc496fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your best-saved model file\n",
    "MODEL_PATH = './models_final/best_final_model_augmented.h5'\n",
    "\n",
    "# Paths to your pre-processed, original (non-augmented) test data\n",
    "X_TEST_PATH = 'X_test_final.npy'\n",
    "Y_TEST_PATH = 'y_test_final.npy'\n",
    "\n",
    "# Path to the original training directory to get the class names in the correct order\n",
    "# Make sure this points to the directory that defines the class order for training\n",
    "TRAIN_DIR_FOR_LABELS = '/data/hjpark/combined_dataset_final/train'\n",
    "\n",
    "\n",
    "def evaluate_final_model():\n",
    "    \"\"\"\n",
    "    Loads a trained Keras model and evaluates its performance on the holdout test set.\n",
    "    \"\"\"\n",
    "    # --- 1. Load Model and Test Data ---\n",
    "    print(\"--- Loading Model and Data ---\")\n",
    "    try:\n",
    "        print(f\"Loading model from: {MODEL_PATH}\")\n",
    "        model = tf.keras.models.load_model(MODEL_PATH)\n",
    "        \n",
    "        print(f\"Loading test data from: {X_TEST_PATH} and {Y_TEST_PATH}\")\n",
    "        X_test = np.load(X_TEST_PATH)\n",
    "        y_test = np.load(Y_TEST_PATH) # These are the ground truth integer labels\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‼️ ERROR: A required file was not found. {e}\")\n",
    "        print(\"Please ensure the model and test .npy files exist at the specified paths.\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during loading: {e}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    print(\"✅ Model and data loaded successfully.\\n\")\n",
    "\n",
    "    # --- 2. Discover Class Labels for the Report ---\n",
    "    try:\n",
    "        # Sort the folder names alphabetically to ensure the order matches the integer labels\n",
    "        target_names = sorted([d for d in os.listdir(TRAIN_DIR_FOR_LABELS) if os.path.isdir(os.path.join(TRAIN_DIR_FOR_LABELS, d))])\n",
    "        print(f\"Found {len(target_names)} classes for reporting: {target_names}\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‼️ WARNING: Could not find training directory at '{TRAIN_DIR_FOR_LABELS}' to get class names.\")\n",
    "        print(\"The classification report will only show integer labels.\")\n",
    "        target_names = None\n",
    "\n",
    "    # --- 3. Generate Predictions ---\n",
    "    print(\"--- Generating Predictions on the Test Set ---\")\n",
    "    # model.predict() returns class probabilities\n",
    "    y_pred_probabilities = model.predict(X_test)\n",
    "    \n",
    "    # Use np.argmax to get the index of the class with the highest probability\n",
    "    y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "    print(\"✅ Predictions generated.\\n\")\n",
    "\n",
    "    # --- 4. Display Evaluation Metrics ---\n",
    "    print(\"--- Final Model Evaluation Report ---\")\n",
    "\n",
    "    if target_names:\n",
    "        # Define the full set of possible labels (0, 1, ..., 9)\n",
    "        full_labels = list(range(len(target_names)))\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        # By providing the `labels` parameter, we tell sklearn about all 10 possible classes,\n",
    "        # fixing the mismatch error.\n",
    "        report = classification_report(y_test, y_pred, labels=full_labels, target_names=target_names, zero_division=0)\n",
    "        print(report)\n",
    "        \n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        # Provide the same labels to the confusion matrix for a consistent, full-sized matrix.\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=full_labels)\n",
    "        print(\"Matrix labels:\", target_names)\n",
    "        print(cm)\n",
    "        print(\"\\n(Rows: True Labels, Columns: Predicted Labels)\")\n",
    "    else:\n",
    "        # Fallback if target names couldn't be loaded\n",
    "        print(\"\\nClassification Report (integer labels only):\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    evaluate_final_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your best-saved model file\n",
    "MODEL_PATH = './models_final/best_final_model_augmented.h5'\n",
    "\n",
    "# Paths to your pre-processed, original (non-augmented) test data\n",
    "X_TEST_PATH = 'X_test_final.npy'\n",
    "Y_TEST_PATH = 'y_test_final.npy'\n",
    "\n",
    "# Path to the original training directory to get the class names in the correct order\n",
    "# Make sure this points to the directory that defines the class order for training\n",
    "TRAIN_DIR_FOR_LABELS = '/data/hjpark/combined_dataset_final/train'\n",
    "\n",
    "# Output paths for visualizations\n",
    "OUTPUT_DIR = './visualizations'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "CM_HEATMAP_PATH = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\n",
    "METRICS_BAR_PATH = os.path.join(OUTPUT_DIR, 'metrics_barplot.png')\n",
    "\n",
    "def evaluate_final_model():\n",
    "    \"\"\"\n",
    "    Loads a trained Keras model and evaluates its performance on the holdout test set.\n",
    "    Generates filtered classification report (only classes in test set) and visualizations.\n",
    "    \"\"\"\n",
    "    # --- 1. Load Model and Test Data ---\n",
    "    print(\"--- Loading Model and Data ---\")\n",
    "    try:\n",
    "        print(f\"Loading model from: {MODEL_PATH}\")\n",
    "        model = tf.keras.models.load_model(MODEL_PATH)\n",
    "        \n",
    "        print(f\"Loading test data from: {X_TEST_PATH} and {Y_TEST_PATH}\")\n",
    "        X_test = np.load(X_TEST_PATH)\n",
    "        y_test = np.load(Y_TEST_PATH)  # These are the ground truth integer labels\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‼️ ERROR: A required file was not found. {e}\")\n",
    "        print(\"Please ensure the model and test .npy files exist at the specified paths.\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during loading: {e}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    print(\"✅ Model and data loaded successfully.\\n\")\n",
    "\n",
    "    # --- 2. Discover Class Labels for the Report ---\n",
    "    try:\n",
    "        # Sort the folder names alphabetically to ensure the order matches the integer labels\n",
    "        target_names = sorted([d for d in os.listdir(TRAIN_DIR_FOR_LABELS) if os.path.isdir(os.path.join(TRAIN_DIR_FOR_LABELS, d))])\n",
    "        print(f\"Found {len(target_names)} classes from training directory: {target_names}\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‼️ WARNING: Could not find training directory at '{TRAIN_DIR_FOR_LABELS}' to get class names.\")\n",
    "        print(\"The classification report will only show integer labels.\")\n",
    "        target_names = None\n",
    "\n",
    "    # --- 3. Generate Predictions ---\n",
    "    print(\"--- Generating Predictions on the Test Set ---\")\n",
    "    # model.predict() returns class probabilities\n",
    "    y_pred_probabilities = model.predict(X_test)\n",
    "    \n",
    "    # Use np.argmax to get the index of the class with the highest probability\n",
    "    y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "    print(\"✅ Predictions generated.\\n\")\n",
    "\n",
    "    # --- 4. Filter to Only Classes Present in Test Set ---\n",
    "    # Get unique classes that actually appear in y_test (support > 0)\n",
    "    unique_test_classes = np.unique(y_test)\n",
    "    print(f\"Classes present in test set: {unique_test_classes}\")\n",
    "    \n",
    "    if target_names:\n",
    "        # Filter target_names to only those in unique_test_classes\n",
    "        filtered_target_names = [target_names[i] for i in unique_test_classes]\n",
    "        # Full labels for CM (but we'll filter the matrix)\n",
    "        full_labels = list(range(len(target_names)))\n",
    "    else:\n",
    "        filtered_target_names = None\n",
    "        full_labels = unique_test_classes  # Use integers if no names\n",
    "\n",
    "    # --- 5. Compute Filtered Classification Report and Confusion Matrix ---\n",
    "    print(\"--- Final Model Evaluation Report (Filtered to Test Set Classes) ---\")\n",
    "    \n",
    "    # Classification Report (filtered by providing only unique_test_classes as labels)\n",
    "    report = classification_report(y_test, y_pred, labels=unique_test_classes, target_names=filtered_target_names, zero_division=0)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Confusion Matrix (full, then filter to present classes)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_test_classes)  # Only for present classes\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"Matrix labels:\", filtered_target_names)\n",
    "    print(cm)\n",
    "    print(\"\\n(Rows: True Labels, Columns: Predicted Labels)\")\n",
    "\n",
    "    # --- 6. Visualizations ---\n",
    "    \n",
    "    # NEW: Abbreviate long class names for a more compact plot\n",
    "    if filtered_target_names:\n",
    "        abbreviated_names = {\n",
    "            'alternate_picking': 'alt_pick', 'sweep_picking': 'swp_pick',\n",
    "            'palm_mute': 'palm_mute', 'harmonics': 'harmonics',\n",
    "            'legato': 'legato', 'picking': 'picking',\n",
    "            'vibrato': 'vibrato', 'slide': 'slide',\n",
    "            'bend': 'bend', 'other': 'other'\n",
    "        }\n",
    "        # Create a new list of labels just for plotting\n",
    "        plot_labels = [abbreviated_names.get(name, name) for name in filtered_target_names]\n",
    "    else:\n",
    "        plot_labels = filtered_target_names\n",
    "\n",
    "    # ADJUSTED: Figure size made more compact\n",
    "    plt.figure(figsize=(8, 7))\n",
    "\n",
    "    # ADJUSTED: Added annot_kws to increase font size of numbers inside the heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=plot_labels, yticklabels=plot_labels,\n",
    "                cbar=True, annot_kws={\"size\": 12}) # Control font size of numbers\n",
    "\n",
    "    # ADJUSTED: Increased font size for readability\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "\n",
    "    # NEW: Added tight_layout to automatically reduce whitespace\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CM_HEATMAP_PATH)\n",
    "    print(f\"✅ Confusion matrix heatmap saved to: {CM_HEATMAP_PATH}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    evaluate_final_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6cb3d9",
   "metadata": {},
   "source": [
    "## Future plan: use transformers (not in scope for this submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
